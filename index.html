<!doctype html>
<html lang="en">
<head>
<title>FunSearch Algorithm and Its Applications</title>
<meta property="og:title" content=FunSearch Algorithm and Its Applications" />
<meta name="twitter:title" content="FunSearch Algorithm and Its Applications" />
<meta name="description" content="Your project about your cool topic described right here." />
<meta property="og:description" content="Your project about your cool topic described right here." />
<meta name="twitter:description" content="Your project about your cool topic described right here." />
<meta property="og:type" content="website" />
<meta name="twitter:card" content="summary" /> 
<meta name="viewport" content="width=device-width,initial-scale=1" />
<!-- bootstrap for mobile-friendly layout -->
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bootstrap@4.6.2/dist/css/bootstrap.min.css" integrity="sha384-xOolHFLEh07PJGoPkLv1IbcEPTNtaed2xpHsD9ESMhqIYd0nLMwNLD69Npy4HI+N" crossorigin="anonymous">
<script src="https://cdn.jsdelivr.net/npm/jquery@3.5.1/dist/jquery.slim.min.js" integrity="sha384-DfXdz2htPH0lsSSs5nCTpuj/zy4C+OGpamoFVy38MVBnE+IbbVYUew+OrCXaRkfj" crossorigin="anonymous"></script>
<script src="https://cdn.jsdelivr.net/npm/bootstrap@4.6.2/dist/js/bootstrap.bundle.min.js" integrity="sha384-Fy6S3B9q64WdZWQUiU+q4/2Lc9npb8tCaSX9FK7E8HnRr0Jz8D6OP9dO5Vg3Q9ct" crossorigin="anonymous"></script>
<link href="https://fonts.googleapis.com/css?family=Open+Sans:300,400,700" rel="stylesheet">
<link href="style.css" rel="stylesheet">

</head>

</head>
<body class="nd-docs">
<div class="nd-pageheader">
 <div class="container">
 <h1 class="lead">
 <nobr class="widenobr">Extending Applications of FunSearch: Cap Set Problem</nobr>
 </h1>
 </div>
</div><!-- end nd-pageheader -->

<div class="container">
<div class="container">
<div class="row">
<div class="col justify-content-center text-center">
<h2> An Analysis of "Mathematical Discoveries From Program Search With Large Language Models"</h2>
<p> By: Claire Pan and Kevin Lu 
<p> Paper Link: <a href = "https://www.nature.com/articles/s41586-023-06924-6">Mathematical Discoveries From Program Search With Large Language Models</a></p>
<p> Our Implementation Link: <a href = "https://github.com/kevinlu4588/funsearch">GitHub (DS4440 Neural Networks Final Project)</a></p>
</div>
</div>

<h2>Introduction</h2>
 <p> In this project, we aim to explore the applicability and extend the findings of the paper "FunSearch: Leveraging LLMs for Evolving Programs to Solve Mathematical and Combinatorial Problems." Our objective is to investigate methods to improve the algorithm's effectiveness in tackling the cap set problem, which is a challenge that were originally addressed in the paper but presents opportunities for further optimization and refinement.
 </p>
 
 <p>
Building upon the foundation laid out in the paper, our project seeks to evaluate algorithm performance on this problem and compare it against traditional heuristic methods. We hope to extend the methodology presented in the paper by exploring the impact of various parameters, such as the number of islands and iterations. Specifically, we will measure how altering these parameters affects the size of cap sets discovered. 
</p>
<p> 
To achieve these objectives, we have implemented the FunSearch algorithm, reproduced the experiments outlined in the paper, and extended our investigations by introducing new experiments with varying parameters. We have also developed a pipeline to collect and analyze data, enabling us to generate graphs that depict the relationship between scores and samples across different experimental setups.
 </p>
 <p> 
By addressing these questions, we aim to not only validate the effectiveness of FunSearch in these domains, but also provide insights into the robustness and scalability of its algorithmic framework. Ultimately, our project aims to contribute to the ongoing research in evolutionary algorithms and their applications in solving complex optimization problems.
 </p>

Main question:

How does changing the number of islands in this genetic programming algorithm affect the evolution and success of its outputs?

How do different LLMs(and thus different code mutators) affect the success of FunSearch outputs?

<h2>Paper Review</h2>
<p>
 This paper introduces FunSearch, an LLM-based approach to tackling challenging mathematical and combinatorial problems. FunSearch iteratively evolves programs via suggestions from the LLM; this LLM is called Codey, and is a pretrained model that is built on top of the PaLM2 model family. Codey is a fast-inference model, meaning that is can quickly process input data and generate predictions (rather than a slower-inference, higher-quality model). Next, a distributed system comprised of three types of workers is used to store initial user-provided programs: the programs database stores and serves programs to FunSearch, the samplers query the database for prompts to guide the generation of new programs, and finally the evaluators assess the generated program performance by executing them on inputs of interest and providing feedback. 
</p>
  <center><img src="https://media.springernature.com/full/springer-static/image/art%3A10.1038%2Fs41586-023-06924-6/MediaObjects/41586_2023_6924_Fig1_HTML.png?as=webp"style="width:700px; height:350px;"></img><br><br></center>

 <p>
  The algorithm skeleton provided by FunSearch serves as a template for program evolution and is demonstrated in this paper on two different problem domains: cap set construction and online bin packing. Researchers found that in the cap set problem, FunSearch was able to exceed traditional methods by discovering larger cap sets in higher dimensions where brute-force approaches were impractical. Similarly, in the online bin packing problem, FunSearch was able to outperform traditional heuristics by evolving more effective packing strategies. Overall, FunSearch offers scalability, flexibility, and enhanced performance over existing approaches, showcasing its potential to address a wide range of challenging optimization problems.  
 </p>

  <p>
In our research, we chose on research FunSearch's abilities in the cap set problem, which is known as one of the best known problems in additive combinatrics. The cap set problem refers to finding the largest posible set of vectors in a finite field such that no three elements in the set can sum up to zero. As this problem has been consistently debated and investigated within mathematics, we thought it would be interesting to push the boundaries of FunSearch in finding the largest possible cap set in `n` dimensions. 
 </p>

  <p>
   In addition to its approach to tackling mathematical and combinatorial problems, FunSearch incorporates an island mechanism within its evolutionary algorithm framework. This allows for greater efficiency and effectiveness of program evolution by leveraging parallelism and diversity maintenance strategies- by partitioning the population of programs into multiple islands, FunSearch enables simultaneous exploration of different evolutionary paths, similar to conducting several smaller experiments concurrently. Since there is a periodic resetting of low-performing islands, this ensures that better evolutionary trajectories are not prematurely abandoned, which allows for continued exploration and adaptation within each island.
 </p>

   <p>
    It is important to note that within each island, programs are clustered based on their signature, allowing for targeted sampling and selection procedures that prioritize high-scoring clusters while still preserving diversity within islands. A signature refers to the program's performance score on each test case, such as the size of a cap set for each input value. Thus, programs that perform similarly across different inputs are grouped togehter into clusters. This clustering and selection mechanism helps the FunSearch algorithm navigate the program space more effectively, avoiding stagnation in local minima. This island mechanism enhances the scalability, adaptability, and robustness of FunSearch, thus, we hope to extend on this research by applying FunSearch to the cap set problem and evaluating the scores.
 </p>
 <center><img src="images/Island1.png" class="implement"></center>

 <center><img src="images/Island2.png" class="implement"></center>

<h2>Method</h2>

<p>
  In order to implement FunSearch, we first connected to OpenAI 3.5 Turbo via their API and registered for a key with $5 worth of credits.  For generating capset solutions,  LLMs are prompted in the form of: 

  </p>


 <div id="container">
    <a href="#">
        <figure>
            <img src=images/Prompt1.png class="implement1" />
            <figcaption>Sample Prompt</figcaption>
        </figure>
    </a>
    <a href="#">
        <figure>
             <img src="images/Palm Response.png" class="implement1" />
            <figcaption>Example Response From Palm2</figcaption>
        </figure>
    </a>
      <a href="#">
        <figure>
             <img src='images/Prompt2.png ' class="implement1" />
            <figcaption>Code To Be Evolved By LLM</figcaption>
        </figure>
    </a>
      <a href="#">
        <figure>
             <img src='images/GPT Response.png' class="implement1" />
            <figcaption>Example Response from GPT-3.5</figcaption>
        </figure>
    </a>


  
</div>
   
<!-- 
      <div class="grid-item"><img class="implement" src="images/Prompt1.png"></div>
      <div class="grid-item"><img class="implement" src="images/Palm Response.png"></div>
      <div class="grid-item"><img class="implement" src="images/Prompt2.png"></div>
      <div class="grid-item"><img class="implement" src="images/GPT Response.png"></div> -->
  </div>
  
<p>

This capset specification provides a skeleton of code that the LLM with evolve over many iterations.  It defines a baseline greedy algorithm for generating capsets(initially of size 2048 for dimension 11)
The returned code is then run in a Docker sandbox(developed by jonppe on Github) and the performance of the solution evaluated.  This is where we extended the implementation of the original funsearch paper, by examining the # of islands as a hyperparameter upon which we can perform a search. 

<center><img class = "implement" src = "images/Analyse Implementation.png"> </center>

Here, we injected a file readout from the sandbox run and added the program to the program database. This allows us to further examine the performance and behavior of programs generated with different islands as a hyperparameter.

Further investigation into alternative LLMs:

In addition to Open-AI's GPT-3.5, we also experimented with Google's Palm2 model and are investigating a fine-tuned version of starcoder.

Using the PyPI library ("llm"), we were able to "plug and play" with various models and compare their performance with the FunSearch evolutionary algorithm.

</p>
<center><img src="images/Different LLM models.png" class="implement"></center>
<p>
  In order to fine-tune the starcoder model, we used the <a href="https://huggingface.co/datasets/smangrul/hf-stack-v1?row=3">mangrul/hf-stack-v1</a> dataset available on Hugging Face as well as their open source starcoder model.
</p>
<center><img src="images/Dataset.png" class="implement"></center>
<p>
  To further reduce the size of the model(we ran out of memory on Google Colab really fast), we utilized the Low Rank Adaptation Technique(LoRA):
</p>
<center><img src="images/LoRA.png" class="implement"></center>
<p> Unfortunately, attempting to train on Colab still didn't work, so our next steps are to utilize the Northeastern RC Cluster(single gpu training) to try and finetune this model.</p>

<h2>Findings</h2>

<p>
  Our findings indicate that the number of islands in the genetic programming algorithm has a significant impact on the evolution and success of its outputs. Specifically, we observed that increasing the number of islands led to a more diverse set of programs being generated, which in turn increased the likelihood of discovering high-performing solutions. This suggests that the algorithm benefits from a higher degree of exploration in the search space, which is facilitated by the parallelism introduced by multiple islands.
  However, increasing the number of islands also drives up computation costs and # of API calls in total.

  In order to account for this, we limited the number of "samples" (API calls) to under 100.  Thus, 4 experiments were run with this in mind, with the number of islands increasing to a higher multiple of 5 each time.

  <div class="grid-container">
    <div class="grid-item"><img class='implement' src="images/5 Islands Capset.png"></div>
    <div class="grid-item"><img class='implement' src="images/Capset 10 Islands.png"></div>
    <div class="grid-item"><img class='implement' src="images/Capset 1 Island.png"></div>
    <div class="grid-item"><img class='implement' src="images/15 Islands.png"></div>
  </div>
  
  We found an 10 islands to be optimal, as this creates a larger spread of diversity while providing each island with an adequate number of iterations for advancing evolution of programs.
  <center><img src="images/Capset max performance.png" class = "implement"></center>
  <center><img src="images/PALM Capset.png"></center>
</p>
<h2>Conclusion</h2>
In conclusion, our study looks into the application of the FunSearch algorithm in tackling the cap set problem, and has provided valuable insights into the dynamics of program evolution. Through different experimentation, we have demonstrated the significant impact of adjusting the number of islands in the genetic programming algorithm, researching the balance between exploration and computational efficiency. Our overall findings suggest that a higher number of islands (optimally 10 islands) creates greater diversity among generated programs, leading to the discovery of more effective solutions. However, this enhancement comes at the cost of increased computational resources. Looking ahead, our research begins to lay some framework for further exploration into refining evolutionary algorithms and their practical applications, and helps future researchers better understand the ways in which the FunSearch algorithm can be better implemented and refined for greater efficiency and accuracy. 
<h2>References</h2>
 
 <p>[1] Romera-Paredes, B., Barekatain, M., Novikov, A. et al. <a href="https://doi.org/10.1038/s41586-023-06924-6">
  <em>Mathematical discoveries from program search with large language models. </em> </a>Nature 625, 468 - 475 (2024).
</p>

  <p>[2] Mouret, J.-B.<a href="https://www.nature.com/articles/d41586-023-03998-0">
  <em>Large language models help computer programs to evolve.</em> </a>Nature 625, 452 - 453 (2024).
</p>
 

<h2>Team Members</h2>
 <p>1. Kevin Lu <a href="lu.kev@northeastern.edu">(lu.kev@northeastern.edu</a>)</p>
 <p>2. Claire Pan <a href="pan.cl@northeastern.edu">(pan.cl@northeastern.edu</a>)</p>

  
</div><!--row -->
</div> <!-- container -->

<footer class="nd-pagefooter">
  <div class="row">
    <div class="col-6 col-md text-center">
      <a href="https://ds4440.baulab.info/">About DS 4440: Practical Deep Networks</a>
    </div>
  </div>
</footer>

</body>
<script>
$(document).on('click', '.clickselect', function(ev) {
  var range = document.createRange();
  range.selectNodeContents(this);
  var sel = window.getSelection();
  sel.removeAllRanges();
  sel.addRange(range);
});
// Google analytics below.
window.dataLayer = window.dataLayer || [];
</script>

</html>

<style>
  body, td, th {
    font-family: 'Open Sans', sans-serif;
  }
  h2 {
    margin-top: 3ex;
  }
  /* Deep blues */
  .color-primary-0 { color: #233BF5 }
  .color-primary-1 { color: #3314DE }
  .color-primary-2 { color: #7717FA }
  .color-primary-3 { color: #1461DE }
  .color-primary-4 { color: #17A9FA }
  
  .nd-pageheader {
    padding: 2rem 15px;
    margin-bottom: 1.5rem;
    color: white;
    text-align: center;
    background-color: #233BF5;
  }
  
  .nd-pageheader a, .nd-pageheader a.likelink {
    color: #e4f1fe;
  }
  
  .nd-pagefooter {
    color: white;
    margin-top: 1.5rem;
    padding: 1rem;
    text-align: center;
    background-color: #233BF5;
  }
  
  .nd-pagefooter a {
    color: #e4f1fe;
  }
  
  .nd-pageheader .container {
    position: relative
  }
  
  .nd-pageheader address {
    font-weight: 300;
  }
  
  .nd-pageheader p, .nd-pageheader h1 {
    margin-bottom: 0.75rem;
    font-size: 2.25rem;
    font-weight: 300;
    line-height: 1.3;
  }
  
  .implement{
    margin-top: 2rem;
    margin-bottom: 2rem;
    width: 600px;
  }
    
  .implement1{
    margin-top: 2rem;
    margin-bottom: 2rem;
    width: 400px;
  }
  .flex-container {
  display: grid;
  flex-wrap: wrap;
  justify-content: center; /* align items in the center horizontally */
  }
  .grid-container {
    display: grid;
    grid-template-columns: auto auto;
    grid-gap: 10px;
    padding: 10px;
  }
  .grid-item {
    text-align: center;
  }
  .citation {
    margin-top: 15px;
    clear: both;
  }
  .citation:after {
    content: '';
    display: table;
    clear: both;
  }
  .citation img {
    float: left;
    margin: 0 10px 10px 0;
    width: 250px;
  }
  nobr.widenobr {
    white-space: normal;
  }
 #container {
    text-align: center;
      font-family: 'Open Sans', sans-serif;
    font-weight: bold;
    font-color: black; 
}
a, figure {
    display: inline-block;
     font-family: 'Open Sans', sans-serif;
    font-weight: bold;
    font-color: black; 
}
figcaption {
    margin: 10px 0 0 0;
    font-family: 'Open Sans', sans-serif;
    font-weight: bold;
    font-color: black; 
}
figure {
    padding: 5px;
}

  
</style>
